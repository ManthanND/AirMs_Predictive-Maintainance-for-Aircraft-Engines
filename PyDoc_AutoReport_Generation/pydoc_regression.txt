C:\3d_reconstruction>python -m pydoc model_selection_regression
R^2 training: 0.580, R^2 test: 0.405
R^2 training: 0.579, R^2 test: 0.408
R^2 training: 0.580, R^2 test: 0.408
R^2 training: 0.626, R^2 test: 0.370
R^2 training: 0.625, R^2 test: 0.403
C:\Users\admin\AppData\Local\Programs\Python\Python36\lib\site-packages\sklearn\model_selection\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.
  FutureWarning
Optimal number of features : 5
The selected features are: ['s4', 's7', 's9', 's11', 's12']
(20631, 24)
R^2 training: 0.594, R^2 test: 0.525
Help on module model_selection_regression:

NAME
    model_selection_regression - Model Selection - Regression_Plane.ipynb

DESCRIPTION
    Automatically generated by Colaboratory.

    Original file is located at
        https://colab.research.google.com/drive/1PB3YVef1fjOAzZqjgFB2zqICqwvMRXQm

FUNCTIONS
    get_regression_metrics(model, actual, predicted)
        Calculate main regression metrics.

        Args:
            model (str): The model name identifier
            actual (series): Contains the test label values
            predicted (series): Contains the predicted values

        Returns:
            dataframe: The combined metrics in single dataframe

    plot_features_weights(model, weights, feature_names, weights_type='c')
        Plot regression coefficients weights or feature importance.

        Args:
            model (str): The model name identifier
            weights (array): Contains the regression coefficients weights or feature importance
            feature_names (list): Contains the corresponding features names
            weights_type (str): 'c' for 'coefficients weights', otherwise is 'feature importance'

        Returns:
            plot of either regression coefficients weights or feature importance

    plot_residual(model, y_train, y_train_pred, y_test, y_test_pred)
        Print the regression residuals.

        Args:
            model (str): The model name identifier
            y_train (series): The training labels
            y_train_pred (series): Predictions on training data
            y_test (series): The test labels
            y_test_pred (series): Predictions on test data

        Returns:
            Plot of regression residuals

DATA
    X_test =     setting1  setting2  setting3      s1      s2...8  100.0  ...
    X_test_poly = array([[ 1.00000000e+00, -6.00000000e-04,  4.000...49769...
    X_test_trn = array([[1398.91,  554.42, 9056.4 ,   47.23,  521...  [142...
    X_train =        setting1  setting2  setting3      s1     ... 100.0  3...
    X_train_poly = array([[ 1.00000000e+00, -7.00000000e-04, -4.000...4722...
    X_train_trn = array([[1400.6 ,  554.36, 9046.19,   47.47,  521...  [14...
    df_test =      id  cycle  setting1  setting2  setting3    ...20       ...
    df_train =         id  cycle  setting1  setting2  setting3 ...        ...
    f = <_io.TextIOWrapper name='fig/mytree.dot' mode='r' encoding='cp1252...
    feats = {'s11': 0.6829670473943875, 's12': 0.0339933184348639, 's4': 0...
    feature = 's12'
    features = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4'...
    features_adxf = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3',...
    features_corrl = ['s2', 's3', 's4', 's6', 's7', 's8', 's9', 's11', 's1...
    features_lowcr = ['setting3', 's1', 's10', 's18', 's19', 's16', 's5', ...
    features_orig = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3',...
    importance = 0.0339933184348639
    importances =      Importance
    s4     0.091236
    s7     0.022947
    s9     0...
    kfold = KFold(n_splits=5, random_state=10, shuffle=False)
    lasso = Lasso(alpha=0.001)
    lasso_metrics =                              LASSO
    Root Mean Squ...   ...
    linreg = LinearRegression()
    linreg_metrics =                          Linear Regression
    Root ...40...
    poly = PolynomialFeatures()
    polyreg = LinearRegression()
    polyreg_metrics =                          Polynomial Regression
    R...9...
    rdg = Ridge(alpha=0.01)
    rdg_metrics =                          Ridge Regression
    Root M....4082...
    reg_metrics_bfe =                          Linear Regression      ...5...
    sel_features = ['s4', 's7', 's9', 's11', 's12']
    y_test = 0     112
    1      98
    2      69
    3      82
    4      9...17
    99     ...
    y_test_predict = array([151.57840788, 119.26851287,  74.41564671,...65...
    y_train = 0        191
    1        190
    2        189
    3        ...630      ...
    y_train_predict = array([150.18610331, 145.67102249, 154.72131664,... ...

FILE
    c:\model_selection_regression.py